{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "eaac7d50-54af-47cb-bd6b-08a910f5a468",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned dataset loaded successfully.\n",
      "Dataset Shape: (91713, 186)\n",
      "\n",
      "Data Preview:\n",
      "   encounter_id  patient_id  hospital_id  hospital_death   age    bmi  \\\n",
      "0         66154       25312          118               0  68.0  22.73   \n",
      "1        114252       59342           81               0  77.0  27.42   \n",
      "2        119783       50777          118               0  25.0  31.95   \n",
      "3         79267       46918          118               0  81.0  22.64   \n",
      "4         92056       34377           33               0  19.0    NaN   \n",
      "\n",
      "   elective_surgery  ethnicity gender  height  ... aids cirrhosis  \\\n",
      "0                 0  Caucasian      M   180.3  ...  0.0       0.0   \n",
      "1                 0  Caucasian      F   160.0  ...  0.0       0.0   \n",
      "2                 0  Caucasian      F   172.7  ...  0.0       0.0   \n",
      "3                 1  Caucasian      F   165.1  ...  0.0       0.0   \n",
      "4                 0  Caucasian      M   188.0  ...  0.0       0.0   \n",
      "\n",
      "   diabetes_mellitus hepatic_failure immunosuppression  leukemia  lymphoma  \\\n",
      "0                1.0             0.0               0.0       0.0       0.0   \n",
      "1                1.0             0.0               0.0       0.0       0.0   \n",
      "2                0.0             0.0               0.0       0.0       0.0   \n",
      "3                0.0             0.0               0.0       0.0       0.0   \n",
      "4                0.0             0.0               0.0       0.0       0.0   \n",
      "\n",
      "   solid_tumor_with_metastasis  apache_3j_bodysystem  apache_2_bodysystem  \n",
      "0                          0.0                Sepsis       Cardiovascular  \n",
      "1                          0.0           Respiratory          Respiratory  \n",
      "2                          0.0             Metabolic            Metabolic  \n",
      "3                          0.0        Cardiovascular       Cardiovascular  \n",
      "4                          0.0                Trauma               Trauma  \n",
      "\n",
      "[5 rows x 186 columns]\n",
      "\n",
      "Data Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 91713 entries, 0 to 91712\n",
      "Columns: 186 entries, encounter_id to apache_2_bodysystem\n",
      "dtypes: float64(170), int64(8), object(8)\n",
      "memory usage: 130.1+ MB\n",
      "None\n",
      "Cleaned dataset loaded successfully.\n",
      "Dictionary Shape: (188, 6)\n",
      "\n",
      "Data Preview:\n",
      "      Category   Variable Name Unit of Measure Data Type  \\\n",
      "0   identifier    encounter_id             NaN   integer   \n",
      "1   identifier     hospital_id             NaN   integer   \n",
      "2   identifier      patient_id             NaN   integer   \n",
      "3  demographic  hospital_death             NaN    binary   \n",
      "4  demographic             age           Years   numeric   \n",
      "\n",
      "                                         Description Example  \n",
      "0  Unique identifier associated with a patient un...     NaN  \n",
      "1       Unique identifier associated with a hospital     NaN  \n",
      "2        Unique identifier associated with a patient     NaN  \n",
      "3  Whether the patient died during this hospitali...       0  \n",
      "4           The age of the patient on unit admission     NaN  \n",
      "\n",
      "Data Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 188 entries, 0 to 187\n",
      "Data columns (total 6 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   Category         188 non-null    object\n",
      " 1   Variable Name    188 non-null    object\n",
      " 2   Unit of Measure  142 non-null    object\n",
      " 3   Data Type        188 non-null    object\n",
      " 4   Description      187 non-null    object\n",
      " 5   Example          178 non-null    object\n",
      "dtypes: object(6)\n",
      "memory usage: 8.9+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score, roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Define the file path\n",
    "data_path = \"D:/Datathon 3/Datathon3_GOSSIS_MIT.csv\"\n",
    "dictionary_path = \"D:/Datathon 3/Datathon3_GOSSIS_MIT_Data Dictionary.csv\"\n",
    "# Load the dataset\n",
    "df = pd.read_csv(data_path)\n",
    "\n",
    "# load the data dictionary \n",
    "dictionary_df = pd.read_csv(dictionary_path)\n",
    "\n",
    "\n",
    "# Confirm successful load\n",
    "print(\"Cleaned dataset loaded successfully.\")\n",
    "print(f\"Dataset Shape: {df.shape}\")  # Check rows & columns\n",
    "print(\"\\nData Preview:\")\n",
    "print(df.head())  # Display first 5 rows\n",
    "\n",
    "# Check data types and missing values\n",
    "print(\"\\nData Info:\")\n",
    "print(df.info())\n",
    "\n",
    "# Confirm successful load\n",
    "print(\"Cleaned dataset loaded successfully.\")\n",
    "print(f\"Dictionary Shape: {dictionary_df.shape}\")  # Check rows & columns\n",
    "print(\"\\nData Preview:\")\n",
    "print(dictionary_df.head())  # Display first 5 rows\n",
    "\n",
    "# Check data types and missing values\n",
    "print(\"\\nData Info:\")\n",
    "print(dictionary_df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7e8f51ad-7422-412a-8f1b-845df2b325dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df shape after keep: (91713, 146)\n"
     ]
    }
   ],
   "source": [
    "# Keep all categories of coulmns except APACHE 'APACHE prediction' 'APACHE comorbidity'\n",
    "# 'APACHE grouping' 'GOSSIS example prediction'\n",
    "\n",
    "categories_to_keep = [\"identifier\",\"demographic\", \"vitals\",\"labs\",\"labs blood gas\"]\n",
    "\n",
    "# Get all columns that have categories not in categories_to_keep\n",
    "cols_to_drop = dictionary_df.loc[\n",
    "    ~dictionary_df[\"Category\"].isin(categories_to_keep),  # \"~\" means \"NOT in\"\n",
    "    \"Variable Name\"\n",
    "].tolist()\n",
    "\n",
    "df = df.drop(columns=cols_to_drop, errors=\"ignore\")\n",
    "print(\"df shape after keep:\", df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a39ed397-ffb5-4be5-916c-5881d33a614b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total numeric columns (excluding target): 139\n",
      "\n",
      "Top 10 columns with the most NaNs:\n",
      " h1_bilirubin_min        84619\n",
      "h1_bilirubin_max        84619\n",
      "h1_lactate_max          84369\n",
      "h1_lactate_min          84369\n",
      "h1_albumin_min          83824\n",
      "h1_albumin_max          83824\n",
      "h1_pao2fio2ratio_min    80195\n",
      "h1_pao2fio2ratio_max    80195\n",
      "h1_arterial_ph_max      76424\n",
      "h1_arterial_ph_min      76424\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Numeric Pipeline Step 1: Identify numeric columns (excluding target)\n",
    "\n",
    "target_col = 'hospital_death'  # Adjust if your outcome is named differently\n",
    "\n",
    "numeric_cols = []\n",
    "for col in df.columns:\n",
    "    # We'll keep only columns that are numeric (float/int)\n",
    "    # and are not the target column\n",
    "    if col != target_col and pd.api.types.is_numeric_dtype(df[col]):\n",
    "        numeric_cols.append(col)\n",
    "\n",
    "print(\"Total numeric columns (excluding target):\", len(numeric_cols))\n",
    "print(\"First 10 numeric columns:\", numeric_cols[:10])\n",
    "\n",
    "\n",
    "# Now let's see how many NaNs each numeric column has\n",
    "na_counts = df[numeric_cols].isna().sum().sort_values(ascending=False)\n",
    "print(\"\\nTop 10 columns with the most NaNs:\\n\", na_counts.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f3c2900b-8556-4574-8d6e-53f76840c6c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns exceeding 80% missingness:\n",
      " []\n",
      "\n",
      "After dropping high-NaN columns, numeric_cols count = 104\n"
     ]
    }
   ],
   "source": [
    "# Numeric Pipeline Step 2: Drop columns with >80% missingness\n",
    "\n",
    "nrows = len(df)\n",
    "threshold = 0.8  # i.e., 80%\n",
    "cols_to_drop = []\n",
    "\n",
    "for col in numeric_cols:\n",
    "    missing_frac = df[col].isna().mean()\n",
    "    if missing_frac > threshold:\n",
    "        cols_to_drop.append(col)\n",
    "\n",
    "print(\"Columns exceeding 80% missingness:\\n\", cols_to_drop)\n",
    "\n",
    "df.drop(columns=cols_to_drop, inplace=True, errors='ignore')\n",
    "\n",
    "# Update numeric_cols to remove dropped columns\n",
    "numeric_cols = [c for c in numeric_cols if c not in cols_to_drop]\n",
    "\n",
    "print(f\"\\nAfter dropping high-NaN columns, numeric_cols count = {len(numeric_cols)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f6da3b97-7beb-4f56-bc10-d6811975374f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After mean imputation, total NaNs in numeric DataFrame: 0\n",
      "Step: Mean imputation done. No more NaNs in numeric columns.\n"
     ]
    }
   ],
   "source": [
    "# Numeric Pipeline Step 3: Mean-impute remaining NaNs\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "\n",
    "df_numeric = df[numeric_cols]  # Sub-DataFrame of numeric features\n",
    "\n",
    "# Fit & transform for imputation\n",
    "df_numeric_imputed = imputer.fit_transform(df_numeric)\n",
    "\n",
    "# Convert back to DataFrame with original column names\n",
    "df_numeric_imputed = pd.DataFrame(df_numeric_imputed, columns=numeric_cols, index=df.index)\n",
    "\n",
    "# Check how many NaNs remain\n",
    "na_count = df_numeric_imputed.isna().sum().sum()\n",
    "print(\"After mean imputation, total NaNs in numeric DataFrame:\", na_count)\n",
    "\n",
    "# Update your main df\n",
    "df[numeric_cols] = df_numeric_imputed\n",
    "\n",
    "print(\"Step: Mean imputation done. No more NaNs in numeric columns.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "76330158-b37f-46ce-b83a-3bf032c8dde2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['identifier' 'demographic' 'APACHE covariate' 'vitals' 'labs'\n",
      " 'labs blood gas' 'APACHE prediction' 'APACHE comorbidity'\n",
      " 'APACHE grouping' 'GOSSIS example prediction']\n"
     ]
    }
   ],
   "source": [
    "unique_vals = dictionary_df['Category'].unique()\n",
    "print(unique_vals)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "48a73f48-ef06-494d-925f-ac9a5dd099b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zero-variance columns: []\n",
      "\n",
      "After removing zero-variance cols, numeric_cols count = 104\n"
     ]
    }
   ],
   "source": [
    "# Numeric Pipeline Step 4: Drop zero-variance columns\n",
    "\n",
    "df_numeric_imputed = df[numeric_cols]  # The numeric features after imputation\n",
    "\n",
    "stds = df_numeric_imputed.std(axis=0)\n",
    "zero_var_cols = stds[stds == 0].index.tolist()\n",
    "\n",
    "print(\"Zero-variance columns:\", zero_var_cols)\n",
    "\n",
    "if zero_var_cols:\n",
    "    df.drop(columns=zero_var_cols, inplace=True)\n",
    "    numeric_cols = [c for c in numeric_cols if c not in zero_var_cols]\n",
    "\n",
    "print(\"\\nAfter removing zero-variance cols, numeric_cols count =\", len(numeric_cols))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a6a3a3df-b430-4eef-9f15-7e40dd5240e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data Preview:\n",
      "   encounter_id  patient_id  hospital_id  hospital_death   age        bmi  \\\n",
      "0       66154.0     25312.0        118.0               0  68.0  22.730000   \n",
      "1      114252.0     59342.0         81.0               0  77.0  27.420000   \n",
      "2      119783.0     50777.0        118.0               0  25.0  31.950000   \n",
      "3       79267.0     46918.0        118.0               0  81.0  22.640000   \n",
      "4       92056.0     34377.0         33.0               0  19.0  29.185818   \n",
      "\n",
      "   elective_surgery  ethnicity gender  height  ... d1_pao2fio2ratio_max  \\\n",
      "0               0.0  Caucasian      M   180.3  ...           285.667079   \n",
      "1               0.0  Caucasian      F   160.0  ...            54.800000   \n",
      "2               0.0  Caucasian      F   172.7  ...           285.667079   \n",
      "3               1.0  Caucasian      F   165.1  ...           342.500000   \n",
      "4               0.0  Caucasian      M   188.0  ...           285.667079   \n",
      "\n",
      "  d1_pao2fio2ratio_min  h1_arterial_pco2_max h1_arterial_pco2_min  \\\n",
      "0           223.523037                   NaN                  NaN   \n",
      "1            51.000000                  37.0                 37.0   \n",
      "2           223.523037                   NaN                  NaN   \n",
      "3           236.666667                  36.0                 33.0   \n",
      "4           223.523037                   NaN                  NaN   \n",
      "\n",
      "  h1_arterial_ph_max  h1_arterial_ph_min  h1_arterial_po2_max  \\\n",
      "0                NaN                 NaN                  NaN   \n",
      "1               7.45                7.45                 51.0   \n",
      "2                NaN                 NaN                  NaN   \n",
      "3               7.37                7.34                337.0   \n",
      "4                NaN                 NaN                  NaN   \n",
      "\n",
      "   h1_arterial_po2_min  h1_pao2fio2ratio_max  h1_pao2fio2ratio_min  \n",
      "0                  NaN                   NaN                   NaN  \n",
      "1                 51.0                  51.0                  51.0  \n",
      "2                  NaN                   NaN                   NaN  \n",
      "3                265.0                 337.0                 337.0  \n",
      "4                  NaN                   NaN                   NaN  \n",
      "\n",
      "[5 rows x 146 columns]\n",
      "\n",
      "Data Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 91713 entries, 0 to 91712\n",
      "Columns: 146 entries, encounter_id to h1_pao2fio2ratio_min\n",
      "dtypes: float64(138), int64(2), object(6)\n",
      "memory usage: 102.2+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    " \n",
    "print(\"\\nData Preview:\")\n",
    "print(df.head())  # Display first 5 rows\n",
    "\n",
    "# Check data types and missing values\n",
    "print(\"\\nData Info:\")\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "79c37a4d-4c51-4edf-8a44-9cf24b579e4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (91713, 104)\n",
      "y shape: (91713,)\n",
      "X_train shape: (64199, 104) y_train shape: (64199,)\n",
      "X_test shape: (27514, 104) y_test shape: (27514,)\n"
     ]
    }
   ],
   "source": [
    "# Numeric Pipeline Step 5: Split into X, y, then train-test split\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "target_col = 'hospital_death'  # Adjust if needed\n",
    "\n",
    "# 1) Build X, y from the DataFrame\n",
    "X = df[numeric_cols].to_numpy()\n",
    "y = df[target_col].to_numpy().astype('float32')\n",
    "\n",
    "print(\"X shape:\", X.shape)\n",
    "print(\"y shape:\", y.shape)\n",
    "\n",
    "# 2) Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=0.3,      # 30% test set\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "print(\"X_train shape:\", X_train.shape, \"y_train shape:\", y_train.shape)\n",
    "print(\"X_test shape:\",  X_test.shape,  \"y_test shape:\",  y_test.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d6e8174c-1ac9-4b10-9cc6-307223a4cfff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done scaling. Checking for any NaNs in scaled sets...\n",
      "NaNs in X_train_scaled: 0\n",
      "NaNs in X_test_scaled: 0\n",
      "Scaling complete. X_train, X_test updated.\n"
     ]
    }
   ],
   "source": [
    "# Numeric Pipeline Step 6: Scale X_train, X_test\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(\"Done scaling. Checking for any NaNs in scaled sets...\")\n",
    "print(\"NaNs in X_train_scaled:\", np.isnan(X_train_scaled).sum())\n",
    "print(\"NaNs in X_test_scaled:\", np.isnan(X_test_scaled).sum())\n",
    "\n",
    "# (Optional) Overwrite X_train, X_test with scaled versions\n",
    "X_train = X_train_scaled\n",
    "X_test = X_test_scaled\n",
    "\n",
    "print(\"Scaling complete. X_train, X_test updated.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "a363f93b-363d-4b76-a6a0-a42eff4761d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes:\n",
      "X_train_t: torch.Size([64199, 104]) y_train_t: torch.Size([64199])\n",
      "X_test_t: torch.Size([27514, 104]) y_test_t: torch.Size([27514])\n",
      "DataLoader created with batch_size = 32\n"
     ]
    }
   ],
   "source": [
    "# Step 7: Convert scaled data to PyTorch tensors & build DataLoader\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# Convert numpy arrays to float32 tensors\n",
    "X_train_t = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_t = torch.tensor(y_train, dtype=torch.float32)\n",
    "\n",
    "X_test_t = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_t = torch.tensor(y_test, dtype=torch.float32)\n",
    "\n",
    "# Create a TensorDataset for the training set\n",
    "train_dataset = TensorDataset(X_train_t, y_train_t)\n",
    "\n",
    "# Define a batch size and create a DataLoader\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "print(\"Shapes:\")\n",
    "print(\"X_train_t:\", X_train_t.shape, \"y_train_t:\", y_train_t.shape)\n",
    "print(\"X_test_t:\", X_test_t.shape, \"y_test_t:\", y_test_t.shape)\n",
    "print(\"DataLoader created with batch_size =\", batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "bad26ea7-cb97-4ee6-94a2-4b219e347930",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model, loss, optimizer re-initialized.\n",
      "Processed 5 batches. Partial losses:\n",
      " [0.6956530213356018, 0.68333500623703, 0.7190823554992676, 0.6102806329727173, 0.6172333359718323]\n"
     ]
    }
   ],
   "source": [
    "# Step 8: Define model, loss, and optimizer\n",
    "# (Re)define the model, loss, optimizer\n",
    "import torch.nn as nn\n",
    "from torch.nn import Sequential, Linear, Tanh, Dropout, Sigmoid\n",
    "from torch.optim import Adam\n",
    "\n",
    "input_dim = X_train_t.shape[1]\n",
    "hidden_units = 16\n",
    "\n",
    "model = Sequential(\n",
    "    Linear(input_dim, hidden_units),\n",
    "    Tanh(),\n",
    "    Dropout(0.2),\n",
    "    Linear(hidden_units, 1),\n",
    "    Sigmoid()\n",
    ")\n",
    "\n",
    "loss_fn = nn.BCELoss()\n",
    "learning_rate = 0.01\n",
    "optimizer = Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "print(\"Model, loss, optimizer re-initialized.\")\n",
    "\n",
    "# Now do the partial training loop on the first 5 batches\n",
    "model.train()\n",
    "epoch_losses = []\n",
    "\n",
    "for i, (X_batch, Y_batch) in enumerate(train_loader):\n",
    "    probs = model(X_batch).view(-1)\n",
    "    loss = loss_fn(probs, Y_batch)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    epoch_losses.append(loss.item())\n",
    "\n",
    "    if i == 4:\n",
    "        break\n",
    "\n",
    "print(f\"Processed {len(epoch_losses)} batches. Partial losses:\\n\", epoch_losses)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "6f9c0f36-95c6-44f3-a48a-bbb29682d47d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5] - Avg training loss: 0.2343\n",
      "Epoch [2/5] - Avg training loss: 0.2236\n",
      "Epoch [3/5] - Avg training loss: 0.2224\n",
      "Epoch [4/5] - Avg training loss: 0.2222\n",
      "Epoch [5/5] - Avg training loss: 0.2210\n"
     ]
    }
   ],
   "source": [
    "# Step 10: Full training loop for multiple epochs\n",
    "\n",
    "epochs = 5  # you can increase this as needed\n",
    "train_loss_history = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    batch_losses = []\n",
    "\n",
    "    for X_batch, Y_batch in train_loader:\n",
    "        # Forward\n",
    "        probs = model(X_batch).view(-1)\n",
    "        loss = loss_fn(probs, Y_batch)\n",
    "\n",
    "        # Backprop\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        batch_losses.append(loss.item())\n",
    "\n",
    "    # Average loss for this epoch\n",
    "    avg_loss = sum(batch_losses) / len(batch_losses)\n",
    "    train_loss_history.append(avg_loss)\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{epochs}] - Avg training loss: {avg_loss:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "093cec5b-c8aa-4bb7-997a-3e8413b81291",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.9226\n",
      "Test Loss: 0.2173\n"
     ]
    }
   ],
   "source": [
    "# Evaluating Accuracy and Loss on the Test Set\n",
    "model.eval()  # set to evaluation mode\n",
    "with torch.no_grad():\n",
    "    # Forward pass on entire X_test\n",
    "    test_probs = model(X_test_t).view(-1)\n",
    "    \n",
    "    # If test_probs is in [0,1], we can do a threshold at 0.5\n",
    "    test_preds = (test_probs >= 0.5).float()\n",
    "    \n",
    "    # Compute binary accuracy\n",
    "    correct = (test_preds == y_test_t).sum().item()\n",
    "    total = y_test_t.shape[0]\n",
    "    test_accuracy = correct / total\n",
    "    \n",
    "    # If we want to compute the average loss\n",
    "    test_loss = loss_fn(test_probs, y_test_t).item()\n",
    "    \n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "print(f\"Test Loss: {test_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "1fb80fe5-185b-4719-8bfe-9b209ea3ebf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[24965   174]\n",
      " [ 1955   420]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Survived       0.93      0.99      0.96     25139\n",
      "        Died       0.71      0.18      0.28      2375\n",
      "\n",
      "    accuracy                           0.92     27514\n",
      "   macro avg       0.82      0.58      0.62     27514\n",
      "weighted avg       0.91      0.92      0.90     27514\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Generate Additional Metrics (Precision, Recall, F1)\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Convert PyTorch tensors to NumPy for scikit-learn\n",
    "test_preds_np = test_preds.numpy()\n",
    "y_test_np = y_test_t.numpy()\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test_np, test_preds_np))\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test_np, test_preds_np, target_names=['Survived', 'Died']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "995b9653-b3da-4fa1-abb8-d2701cd6aa96",
   "metadata": {},
   "source": [
    "# Results\n",
    "the overall accuracy is high (about 92%), the model is missing many of the “Died” cases:\n",
    "\n",
    "Recall for “Died” is only 0.18. This indicates the model correctly identifies only 18% of actual deaths.\n",
    "Precision for “Died” is 0.71, meaning when it does predict death, it's often correct—but it simply doesn't predict death very often.\n",
    "This imbalance between high performance on the majority class (Survived) and poor performance on the minority class (Died) is common in medical classification tasks where one outcome is rarer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "180bab95-becd-4989-9db0-15dd5f9c6c86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgboost imported successfully.\n"
     ]
    }
   ],
   "source": [
    "#XGB Next \n",
    "# Step XGB.1\n",
    "\n",
    "# If needed  \n",
    "# !pip install xgboost\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "print(\"xgboost imported successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "28493297-793b-4a49-96af-b38a9947430f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier trained successfully.\n"
     ]
    }
   ],
   "source": [
    "# Step XGB.2: Define and train an XGBClassifier\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Create an XGBClassifier instance\n",
    "# You can tune hyperparameters like n_estimators, max_depth, learning_rate, etc.\n",
    "xgb_clf = XGBClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Fit on the training data\n",
    "xgb_clf.fit(X_train, y_train)\n",
    "\n",
    "print(\"XGBClassifier trained successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "3733f2eb-070f-4f46-9414-6701948d996e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier Test Accuracy: 0.9290\n",
      "\n",
      "Confusion Matrix:\n",
      "[[24864   275]\n",
      " [ 1678   697]]\n"
     ]
    }
   ],
   "source": [
    "# Step XGB.3: Evaluate XGBClassifier\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "# Predict on the test set\n",
    "xgb_test_preds = xgb_clf.predict(X_test)\n",
    "\n",
    "# Compute accuracy\n",
    "xgb_accuracy = accuracy_score(y_test, xgb_test_preds)\n",
    "\n",
    "print(f\"XGBClassifier Test Accuracy: {xgb_accuracy:.4f}\")\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, xgb_test_preds)\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(cm)\n",
    "\n",
    "# Classification Report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "83b1bde0-0257-4aaa-8131-c35937a546a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Survived       0.94      0.99      0.96     25139\n",
      "        Died       0.72      0.29      0.42      2375\n",
      "\n",
      "    accuracy                           0.93     27514\n",
      "   macro avg       0.83      0.64      0.69     27514\n",
      "weighted avg       0.92      0.93      0.92     27514\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, xgb_test_preds, target_names=[\"Survived\", \"Died\"]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2139a8fe-1091-44a6-9495-153733458183",
   "metadata": {},
   "source": [
    "#XGBoost model has boosted the recall for the “Died” class to 29% (up from 18% in the neural network), though it is still missing many positive cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "0fdbab0c-d1c3-442b-ae57-a7b9f3616758",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=6, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=100, n_jobs=None,\n",
       "              num_parallel_tree=None, random_state=42, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;XGBClassifier<span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=6, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=100, n_jobs=None,\n",
       "              num_parallel_tree=None, random_state=42, ...)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=6, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=100, n_jobs=None,\n",
       "              num_parallel_tree=None, random_state=42, ...)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adjust class imbalance\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "negative_count = (y_train == 0).sum()\n",
    "positive_count = (y_train == 1).sum()\n",
    "scale_pos_weight = negative_count / positive_count\n",
    "\n",
    "xgb_clf = XGBClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.1,\n",
    "    random_state=42,\n",
    "    scale_pos_weight=scale_pos_weight\n",
    ")\n",
    "xgb_clf.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "225b20c5-078d-4ef5-af1f-f90d22662b1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[17447  7692]\n",
      " [  308  2067]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Survived       0.98      0.69      0.81     25139\n",
      "        Died       0.21      0.87      0.34      2375\n",
      "\n",
      "    accuracy                           0.71     27514\n",
      "   macro avg       0.60      0.78      0.58     27514\n",
      "weighted avg       0.92      0.71      0.77     27514\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#threshold tuning \n",
    "import numpy as np\n",
    "probs = xgb_clf.predict_proba(X_test)[:,1]  # probabilities for class=1\n",
    "threshold = 0.3  # e.g., a lower threshold\n",
    "\n",
    "preds_custom = (probs >= threshold).astype('float32')\n",
    "\n",
    "# Evaluate\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "print(confusion_matrix(y_test, preds_custom))\n",
    "print(classification_report(y_test, preds_custom, target_names=['Survived','Died']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4424031a-a25a-4aca-b486-6fd8ea56ec73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "5405ae43-27aa-4591-a02a-cd88f6372fcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 200, 'scale_pos_weight': 10.58826714801444}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'max_depth': [4,6,8],\n",
    "    'learning_rate': [0.01, 0.1],\n",
    "    'n_estimators': [100,200],\n",
    "    'scale_pos_weight': [scale_pos_weight, scale_pos_weight*1.5]\n",
    "}\n",
    "xgb_clf = XGBClassifier(random_state=42)\n",
    "grid = GridSearchCV(xgb_clf, param_grid, scoring='f1', cv=3, n_jobs=-1)\n",
    "grid.fit(X_train, y_train)\n",
    "print(\"Best params:\", grid.best_params_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c755060-5b78-4fff-b289-31d2325149b9",
   "metadata": {},
   "source": [
    "Model\tAccuracy\tSurvived_Precision\tSurvived_Recall\tSurvived_F1\tDied_Precision\tDied_Recall\tDied_F1\n",
    "XGB\t    0.93\t0.94\t0.99\t0.96\t0.72\t0.29\t0.42\n",
    "XGB2\t0.71\t0.98\t0.69\t0.81\t0.21\t0.87\t0.34\n",
    "DL NN\t0.92\t0.93\t0.99\t0.96\t0.71\t0.18\t0.28"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
